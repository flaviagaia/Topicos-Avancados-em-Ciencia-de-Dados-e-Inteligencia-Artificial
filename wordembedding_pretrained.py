# -*- coding: utf-8 -*-
"""WordEmbedding_pretrained.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sKaDCXjDMiJWRO1PHETGcGGKOEr3LA7R

## Explorando um modelo pré-treinado de WordEmbedding

Para ilustrar a estrutura de uma representação em Word Embedding, serão explorados os modelos pré-treinados disponibilizados na biblioteca Gensim.
"""

import gensim.downloader
from gensim.models import KeyedVectors

# Mostrar todos os modelos disponíveis na biblioteca
for model in list(gensim.downloader.info()['models'].keys()): print(model)

# Carregar o mais famoso, cerca de 1.6 GB, 3 milhões de palavras
google300 = gensim.downloader.load('word2vec-google-news-300')

google300.vocab

# tamanho do vocabulario
len(google300.vocab)

# Número de dimensões de cada vetor que representa cada palavra
google300.vector_size

# Palavra mais similar com California
google300.most_similar('California')

# Palavra mais similar com Neymar
google300.most_similar('Neymar')

google300.most_similar('Vasco')

# Representação da operação: 'man' - 'king' = 'woman' - 'queen'
result = google300.most_similar(positive=['man', 'queen'], negative=['king'], topn=1)
print(result)

# Representação da operação: 'France' - 'Paris' = 'Brazil' - 'Brasilia'
result = google300.most_similar(positive=['France', 'Brasilia'], negative=['Brazil'])
print(result)

result = google300.most_similar(positive=['United_States', 'euro'], negative=['Brazil'], topn=8)
result

# Palavra mais similar com cachorro
google300.most_similar('dog')

glover200 = gensim.downloader.load('glove-twitter-200')

len(glover200.wv.vocab)

glover200.vector_size

glover200.most_similar('california')

google300.save('modelGoogle300.bin')

"""Detalhe para o consumo de memória RAM..."""

# Word Embedding em português:
# disponibilizado em http://nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc
!wget http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s300.zip

!unzip /content/download.php?file=embeddings%2Fword2vec%2Fcbow_s300.zip

from gensim.test.utils import datapath
wv_from_text = KeyedVectors.load_word2vec_format(datapath('/content/cbow_s300.txt'), binary=False)

len(wv_from_text.wv.vocab)

wv_from_text.vector_size

wv_from_text.most_similar('Lula')